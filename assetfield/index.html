
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>AssetField</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <link rel="icon" type="image/png" href="../img/newyork.ico">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-110862391-3');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                AssetField: Assets Mining and Reconfiguration in  <br> Ground Feature Plane Representation
            </h1>
        </div>

        <div class="row">
            <div class="col-md-12 text-center">
                <div style="margin-bottom: 0.7em; margin-top:0.2em" class="authors">
                    <a style="color:#000000;" href="https://kam1107.github.io/">Yuanbo Xiangli*<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="https://eveneveno.github.io/lnxu/">Linning Xu*<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="https://xingangpan.github.io/">Xingang Pan<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="http://nxzhao.com/">Nanxuan Zhao<sup>3</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="http://daibo.info/">Bo Dai<sup>4</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a style="color:#000000;" href="http://dahua.me/">Dahua Lin<sup>1,4</sup></a>
                </div>

                <div style="margin-bottom: 0.5em;" class="affiliations">
                    <a href="http://mmlab.ie.cuhk.edu.hk/">The Chinese University of Hong Kong<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://www.mpi-inf.mpg.de/">Max Planck Institute for Informatics<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    
                    </br>
                    <a href="https://www.bath.ac.uk/">University of Bath<sup>3</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  
                    <a href="https://www.shlab.org.cn/">Shanghai Artificial Intelligence Laboratory<sup>4</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  
                </div>

                <div style="margin-bottom: 0.7em;" class="col-md-12 text-center">
                    *denotes equal contribution
                </div>

            </div>
        </div>

        <div style="margin-bottom: 0.7em;" class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="./img/main.pdf">
                            <image src="../img/paper.png" height="50px"><br>
                                <h5><strong>Paper</strong></h5>
                            </a>
                        </li>
                        <li>
                            <image src="../img/github_pad.png" height="50px"><br>
                                <h5><strong>Code (coming soon)</strong></h5>
                            </a>
                        </li>
                        <li>
                            <a href="./img/supp.pdf">
                            <image src="../img/paperclip.png" height="50px"><br>
                                <h5><strong>Supplement</strong></h5>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="./img/teaser.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    Both indoor and outdoor environments (e.g. restaurants
                    and residential areas) are comprised of structured and
                    repetitive components. Traditional modeling pipelines usually
                    keep an asset library that stores template objects, where
                    designers can constantly refer to and deploy their copies
                    in the scene. Inspired by this observation, we present a
                    novel neural scene representation system, namely Asset-
                    Field, which is efficient and scalable by learning a set of
                    object-centric ground feature planes, where an asset library
                    can be automatically extracted. Unlike existing methods
                    which require object masks to query the spatial points at
                    inference time, our ground feature plane representation offers
                    a natural visualization of the scene, on which a variety
                    of operations (e.g. translation, deformation) can be performed
                    to configure a new scene for rendering. Extensive experiments 
                    demonstrate that our system not only achieves
                    competitive performance for novel-view synthesis, but also
                    produces realistic rendering for new scene configurations
                    with a variety of object editing.             
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Framework
                </h3>
                <image src="./img/pipeline.png" class="img-responsive" alt="overview"><br>
                <p class="text-justify">
                    <strong> Overview of AssetField.</strong> The blue box<span style="background-color: #cfe2f3a8">(b)</span> and orange box<span style="background-color: #fce5cdb3">(c-d)</span> show the pipeline of Basic and Improved AssetField respectively.
                    Basic AssetField models a set of separate density and RGB (optionally DINO) fields. Improved AssetField unifies color and semantic field
                    into RGB-DINO ground feature plane that is decoded into 3D with geometry guidance from density occupancy. This further encourages
                    learning an object-centric RGB-DINO plane that is suitable for <span style="background-color: #d9d2e9a8">(e)</span> asset mining and layout discovery. The extracted category template
                    from the asset and layout discovery procedure is then added to the maintained asset library for future usage.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Example Results
                </h3>
                    <h4>
                        # Delete Instances
                    </h4>
                    <image src="./img/results-deletion.png" class="img-responsive" alt="overview">
                    <h4>
                        # Move Instances
                    </h4>
                    <image src="./img/results-translation.png" class="img-responsive" alt="overview">
                    <h4>
                        # Manipulation (rescaling & translation)
                    </h4>
                    <image src="./img/results-move&rescale.png" class="img-responsive" alt="overview">
                    <h4>
                        # Manipulation (rotation & deletion)
                    </h4>
                    <image src="./img/results-rot&del.png" class="img-responsive" alt="overview">
                    <br>
                    <p class="text-justify">
                        <strong> Results of asset mining and scene editing with Improved AssetField.</strong>
                        <span style="background-color: #fce5cdb3">(a)</span> Our approach learns informative density and RGBDINO
                        ground feature planes that support object detection and categorization. <span style="background-color: #d9ead3a8">(b)</span> With joint training, an asset library can be constructed
                        by storing ground feature plane patches of the radiance field (we show label patches here for easy visualization). <span style="background-color: #cfe2f3a8">(c)</span> The proposed ground
                        plane representation provides an explicit visualization of the scene configuration, which be directly manipulated by users. The altered
                        ground feature plane is then fed to the global MLP renderer along with the shared z-axis feature to render views of the novel scenes. Basic
                        operations such as object removal, translation, rotation and rescaling are demonstrated on the right.
                    </p>

                <h3>
                    More results
                </h3>
                <table>
                    <tr>
                    <td width="30%">
                        <video id="v11" width="100%" autoplay loop muted controls>
                            <source src="img/move.mp4" type="video/mp4" />
                        </video>
                    </td>
                    <td width="30%">
                        <video id="v12" width="100%" autoplay loop muted controls>
                            <source src="img/change_appearance.mp4" type="video/mp4" />
                        </video>
                    </td>
                    <td width="30%">
                        <video id="v12" width="100%" autoplay loop muted controls>
                            <source src="img/reconfig_room.mp4" type="video/mp4" />
                        </video>
                    </td>
                </tr>
                </table>                
            </div>
        </div>
        <br>
        <!-- Slideshow container -->
       
<!--         <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Links
                </h3>
            </div>
        </div> -->

        

<!--         <div class="row" id="header_img">
            <figure class="col-md-8 col-md-offset-2">
                <image src="img/llff_teaser.png" class="img-responsive" alt="overview">
                <figcaption>
                </figcaption>
            </figure>
                
        </div> -->

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Technical Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/LY6MgDUzS3M" allowfullscreen style="pbungeeosition:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->
            
        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@inproceedings{xiangli2022bungeenerf,
    title={BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale Scene Rendering},
    author={Xiangli, Yuanbo and Xu, Linning and Pan, Xingang, and Zhao, Nanxuan and Rao, Anyi and Theobalt, Christian and Dai, Bo and Lin, Dahua},
    booktitle = {The European Conference on Computer Vision (ECCV)}, 
    year={2022}
}
                    </textarea>
                </div> -->
</body>

	<script type="text/javascript">
        var slideIndex = 1;
        showSlides(slideIndex);

        // Next/previous controls
        function plusSlides(n) {
        showSlides(slideIndex += n);
        }

        // Thumbnail image controls
        function currentSlide(n) {
        showSlides(slideIndex = n);
        }

        function showSlides(n) {
        var i;
        var slides = document.getElementsByClassName("mySlides");
        var dots = document.getElementsByClassName("dot");
        if (n > slides.length) {slideIndex = 1}
        if (n < 1) {slideIndex = slides.length}
        for (i = 0; i < slides.length; i++) {
            slides[i].style.display = "none";
        }
        for (i = 0; i < dots.length; i++) {
            dots[i].className = dots[i].className.replace(" active", "");
        }
        slides[slideIndex-1].style.display = "block";
        dots[slideIndex-1].className += " active";
        }
	</script>




</html>
